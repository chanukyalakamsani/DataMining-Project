{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy \n",
    "import pandas as pd\n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import tweepy\n",
    "import json\n",
    "from dateutil import parser\n",
    "import time\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_oauthlib import OAuth1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api.update_status(\"Look, I'm tweeting from #Python in my #earthanalytics class! @Data_mining_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'AYPIZONhHffhahNyHVcJEVtEQ'\n",
    "consumer_secret = 'EIiDmUzHjhzVJbcTQW1oOKkXkZ9CxLVxrId7HJUfwhOGd6bM5K'\n",
    "access_token = '718098183650304000-Y0dS4kJIz6wtSfsvRO0EYl2rbErYcUQ'\n",
    "access_token_secret = 'SCtkduBl8Jv9PwdG2W44YsnzKNMforOv3i0WFpvAAWykm'\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    " \n",
    "q = 'premier league -filter:retweets AND -filter:replies'\n",
    " \n",
    "url = 'https://api.Twitter.com/1.1/search/tweets.json' ### url to Twitter API\n",
    " \n",
    "pms = {'q' : q, 'count' : 100, 'lang' : 'en', 'result_type': 'recent'} ### parameters according to Twitter API\n",
    " \n",
    "\n",
    "    \n",
    "auth = OAuth1(consumer_key, consumer_secret, access_token, access_token_secret)\t\n",
    " \n",
    "res = requests.get(url, params = pms, auth=auth)\n",
    "\n",
    "tweets = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'errors': [{'message': 'Rate limit exceeded', 'code': 88}]}\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_params = {\n",
    "    'app_key':'API Key',\n",
    "    'app_secret':'API secret',\n",
    "    'oauth_token':'Access token',\n",
    "    'oauth_token_secret':'Access token secret'\n",
    "}\n",
    "\n",
    "# Creating an OAuth Client connection\n",
    "auth = OAuth1 (\n",
    "    auth_params['app_key'],\n",
    "    auth_params['app_secret'],\n",
    "    auth_params['oauth_token'],\n",
    "    auth_params['oauth_token_secret']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.search(\"python\")\n",
    "for tweet in public_tweets:\n",
    "    if tweet.lang == \"eng\":\n",
    "        print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# url according to twitter API\n",
    "url_rest = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
    "\n",
    "# getting rid of retweets in the extraction results and filtering all replies to the tweet often uncessary for the analysis\n",
    "q = '%40amazonIN -filter:retweets -filter:replies' # Twitter handle of Amazon India\n",
    "\n",
    "# count : no of tweets to be retrieved per one call and parameters according to twitter API\n",
    "params = {'q': q, 'count': 100, 'lang': 'en',  'result_type': 'recent'}\n",
    "results = requests.get(url_rest, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @ENicolson1: All E. Nicolson titles available @ https://t.co/fGzhP31I7n\n",
      "\n",
      "#scifibooks #5stars #paranormal #contemporary #conspiracy https…\n",
      "Some 400 pound person = your rights #breakingnews #reality #askwale #realnews #truth #yourrights #conspiracy #news… https://t.co/AtHcQVmFu5\n",
      "No one ever talks about being on the left side of history. #conspiracy\n",
      "RT @roylehypnotist: @ConspiracyAsylm EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Boo…\n",
      "@PlayablePodcast @MattReiser3 @laughatbrian @catocalvin Fun fact! Wart actually makes a cameo in #LinksAwakening, a… https://t.co/zafoolHFYr\n",
      "Thirteen Across https://t.co/oRm5y8vLj2 #Sponsor #99cents #Conspiracy #Thriller #deal #Seven #stops, Seven sets of… https://t.co/Gq63ansQYc\n",
      "RT @rojawi: Adding Insurrection to the list of impeachable offenses: #Conspiracy #MoneyLaundering #ObstructionOfJustice #Emoluments #CyberC…\n",
      "@ChoudhuriTarit @PRA24 @PMOIndia @nsitharaman @narendramodi Yes. Wat u call a govt, for whom benefiting his friend… https://t.co/vKcYy9Ib3Q\n",
      "RT @shaunattwood: My latest YouTube video: #epstein #clinton #alexjones #infowars #davidicke #princeandrew #maxwell #illuminati #conspiracy…\n",
      "RT @ENicolson1: All E. Nicolson titles available @ https://t.co/fGzhP31I7n\n",
      "\n",
      "#scifibooks #5stars #paranormal #contemporary #conspiracy https…\n",
      "@joemfbrown EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Book… https://t.co/FdPnad69x3\n",
      "RT @KCORRadio: Archive Sept 29, 2019 #insidethematrix @JimiBrent #KCOR #Radio #Technology #Conspiracy #TalkRadio #ConspiracyTheories #awake…\n",
      "@ThelIluminatii EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/W04MWwzegX\n",
      "@ILLUMINATIAM EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Bo… https://t.co/0A6Vdv0Xbu\n",
      "RT @ENicolson1: All E. Nicolson titles available @ https://t.co/fGzhP31I7n\n",
      "\n",
      "#scifibooks #5stars #paranormal #contemporary #conspiracy https…\n",
      "@lIIuminatii EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Boo… https://t.co/BJ37McCY6u\n",
      "RT @danielkemp6: BOTH KINDLES in the Heirs and Descendants Series for ONLY—£3.98 or $5.98 in foreign money.\n",
      "(a third novel next spring)\n",
      "\n",
      "#M…\n",
      "@wesbos @Logitech Mx3 is out. Planned obsolescence. #conspiracy. But I like the new button placements, metal scroll wheels and usb-c\n",
      "@BrainwashingBUT EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/JmrkulvSl9\n",
      "@HPersuaders EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Boo… https://t.co/gepY4B53Eo\n",
      "@BrainwashingDad EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/947DH8sSjc\n",
      "@BrainwashingThe EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/y0RKKB0vFd\n",
      "RT @letsliveinpeace: @matthewamiller They are upset because Ford, GM, Chrysler, and others are building hybrid and electric vehicles. This…\n",
      "Adding Insurrection to the list of impeachable offenses: #Conspiracy #MoneyLaundering #ObstructionOfJustice… https://t.co/HQyvuH9wwj\n",
      "@shinjukushug they are cracking up Hugh ,you really need to give them some hope ,mad john fae greenock ,noo mad joe… https://t.co/PVWTYJK8VC\n",
      "RT @danielkemp6: BOTH KINDLES in the Heirs and Descendants Series for ONLY—£3.98 or $5.98 in foreign money.\n",
      "(a third novel next spring)\n",
      "\n",
      "#M…\n",
      "RT @shaunattwood: My latest YouTube video: #epstein #clinton #alexjones #infowars #davidicke #princeandrew #maxwell #illuminati #conspiracy…\n",
      "@newtgingrich One was for a lie about a sex act between 2 consenting adults.  \n",
      "THIS is for\n",
      "#Treason\n",
      "#Conspiracy… https://t.co/IrjhW3gwCk\n",
      "RT @ENicolson1: All E. Nicolson titles available @ https://t.co/fGzhP31I7n\n",
      "\n",
      "#scifibooks #5stars #paranormal #contemporary #conspiracy https…\n",
      "@TheUriGeller EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Bo… https://t.co/SbcYDv9tzx\n",
      "@EamonnHolmes EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Bo… https://t.co/ZlPQauYoQe\n",
      "@rustyrockets EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Bo… https://t.co/OsxEO2gbrh\n",
      "@NewTruthers EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Boo… https://t.co/nQtYW5efFJ\n",
      "Archive Sept 29, 2019 #insidethematrix @JimiBrent #KCOR #Radio #Technology #Conspiracy #TalkRadio… https://t.co/jUQwouDlHI\n",
      "@ATruthers EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Book… https://t.co/xcT9pARgcQ\n",
      "@ickefr EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Book on… https://t.co/LQsmkczGMG\n",
      "@DavidIcke_Books EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/LSRaPld2dL\n",
      "@StandBy4MindCtl EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/vwJFkzx9BV\n",
      "@realDonaldTrump @WhiteHouse Do you ppl really support a #potus that depends on the latest #conspiracy theories for… https://t.co/dBm8IVgJLc\n",
      "@steveodwyer EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Boo… https://t.co/DLNtxolnoL\n",
      "@mindcontrol2016 EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/AS6ZLswbWq\n",
      "@AnonymousPress EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/6jfIPwbxMF\n",
      "@freeanons EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Book… https://t.co/WJOcim0ZWy\n",
      "@NYTAnon EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose Book on… https://t.co/lq0n23V8ZJ\n",
      "@AnonymousVideo EXTREME DANGER EXTREME HYPNOSIS\n",
      "\n",
      "NEW Feature Film Documentary &amp; Explosive Conspiracy Theory Expose… https://t.co/oTWMvGMmLG\n"
     ]
    },
    {
     "ename": "TweepError",
     "evalue": "Twitter error response: status code = 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-bfc1460cdc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m for tweet in tweepy.Cursor(api.search,q=\"#Conspiracy\",count=1,\n\u001b[1;32m      6\u001b[0m                            \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minclude_rts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                            since=\"2019-09-12\").items():\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print (tweet.created_at, tweet.text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# Parse the response payload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepError\u001b[0m: Twitter error response: status code = 429"
     ]
    }
   ],
   "source": [
    "#csvFile = open('ua.csv', 'a')\n",
    "#Use csv Writer\n",
    "#csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,q=\"#Conspiracy\",count=1,\n",
    "                           lang=\"en\",include_rts=False,\n",
    "                           since=\"2019-09-12\").items():\n",
    "    #print (tweet.created_at, tweet.text)\n",
    "    print(tweet.text)\n",
    "    #csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'uDQREvPbEn48f0F5vIO4q0vMz'\n",
    "        consumer_secret = 'Hpch5tT7KubBOKzJA9I6hfPj4bQ4whnDQfI7FovUhLz8rGrPqA'\n",
    "        access_token = '18098183650304000-TNlXzh6rSYaTp8Epd0FARhSBO7sJ4Rw'\n",
    "        access_token_secret = 'WgcZoK0zuqULnJTM79oWg86zrkg94KER6nNoTbUP7aIMl'\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\")\n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "  \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "  \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Donald Trump', count = 200) \n",
    "    # picking positive tweets from tweets \n",
    "    print(tweets)\n",
    "    \n",
    "    \"\"\"\n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} % \\ \".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
    "  \n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "  \n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text']) \n",
    "        \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : [{'code': 89, 'message': 'Invalid or expired token.'}]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
